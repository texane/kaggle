. todo
 . improve matlab code
  . averaged, quantized + sliced in matlab
  . understand + implement levenberg method
  . saved the set of tids used to train + tests
  . test against fann

 . table interface
  . should have column names
  . binary format for rapid loading
  . stored by column (chosen at load time)
  . table_view
  . actuellement, un probleme est de ne pas nommer les colonnes
   . par exemple, on -3 des fois... ne devrait pas etre le cas
  . l interface devrait permettre de couper les vues, sauvegarder...
  . optimizer les representations binaires

 . parallelisme
  . a default du langage, certains code pourrait etre implementes
  via une library qui masque le travail sur gpu
   . average, stddev...

 . fonctionalites
  . preprocessing
   . subsampling, oversampling
  . classification
   . clustering
  . rarity analysis

. todo
 . impelment a neural network with the root package
 . add non linearity topic
   -> input x N != output x N

. todos
 . ajouter les colonnes concernant les derivees et entrainer le reseau la dessus
  . entrainer seulement sur les derivees? avec amplitudes?
  . recuperer les training set est trop long, depend de la position du set... c est quoi ce bordel!!
 . plan d attaque
  . general: utilisation d un reseau de neurones
  . filtrage des samples d entree
   . algorithme genetique: finir implementation
   . methodes de clustering, reductions des input
   . ce sont des signaux, voir l application du reseau de neurones sur les derivees
  . l algorithme genetique pour filtrer les colonnes n est pas bon
   . deja c est lent, de plus ca ne sort pas des resultats toujours
   coherents
   -> meme si ca a ete teste

. ajout des derivees dans l entrainement du nn
 . entrainement sur les 300 premiers tids
 . soumission, public AUC: 0.758521
 . a peu meilleur que sans
 . nn_do_score(tids = [300:400]) ~= 0.79
 . nn_do_score(tids = [300:210]) ~= 0.71228

 . en utilisant seulement les derivees, on obtient un mauvais score global,
 car beaucoup d individus ont un alertness constant a 0. dans ce cas, notre
 score == 0. Par contre, les bonnes predictions sont vraiment bonnes (score
 moyen >86%) -> il faut voir pourquoi on n arrive pas a predire ce type
 d individus
  . essayer en employant le reseau de neurones entraine normalement
liste
tid: 301
tid: 302
tid: 303
tid: 304
tid: 305
tid: 306
tid: 307
tid: 308
tid: 309
tid: 310

. input data
 . trial id: a trial on one observer
 . 1210 samples of different sources taken every 100 ms (~2min)
  . this can be viewed as a signal
  . important signals: 3 (alert or not)
 . csv format
  . rows contains the samples at a given time for a given trial
  . next row contains the samples at t+1
  . groups of 1210 rows

. some rules
 . using futur values from alertness to predict past alertness
 values is not allowed, since it is not casual

. clasification
 . initial/instantaneous mode
  . used to determine alertness when there is no past values
  . should be able for a given T to tell what is the value of alert(T)
   . based on all the important signals, clusterise according to trained set
   . neural net? -> input

. single signal information
 . the more we are disturb, the more we are alert
 . the more we stay alert, the more likely we are to become not alert

. signal correlation
 . finding the interesting signals
  . consider the alert signal (3) as being the reference one
  . question: find the signal best matching the alert signal
  . candidates: signal 4
  . plot the DCT of both signal, or something equivalent
  . plot spectrograms
  . signals derivative best macthing the reference
 . how much the signal groups contribute to the data
 . take into account the fact there is a phase between some
 signal and isAlert(t)
  -> because we are becoming alert

. octave
 . plot the signal 15 in time in time for trial0
  . data = csvread('/home/texane/dl/fordTrain.csv');
  . subplot(2, 1, 1)
  . plot(data(1:1210,15))
  . subplot(2, 1, 2)
  . plot(data(1:1210,3)) % alert signal

 . signal derivative
  . subplot(3, 1, 1); plot(data(2*(1:1210),4));
  . subplot(3, 1, 2); plot(diff(data(2*(1:1200),4)));
  . subplot(3, 1, 3); plot(data(2*(1:1210),3));

. analyse du signal 20
 . une analyse stat montre que le signal 20 signal maximise
 le instantaneous score alert (68%)
 . si on regarde le comportement de s20, on deduit ce qui suit:
  lorsqu il y a un changement d etat du signal alert ET qu il y a
  un changement d etat dans s20, alors le prochain changement d etat
  de alert se fera avec le changement d etat de s20

. determination instantanee de la valeur de alert
 . ie. pas de memoire, de sample dans le passee
 . il faut entrainer un systeme

. current score: 0.81928
. commandline
 . source 'nn/nn.m'; [nn, mean, std] = nn_train(data); score = nn_score(nn, mean, std, data);
 . source 'nn/nn.m'; [nn, mean, std] = nn_train(data); outs = nn_eval(nn, mean, std, td);
 . source 'nn/nn.m'; nn_submit(td, outs);

 . full script (rev. 407d8329a59105154d2fdad3b393edd62a923de5)
  . source nn/nn.m
  . cols = [4:33];
  . data = nn_csvread('../data/fordTrain.csv');
  . [nn, mean, std] = nn_do_train(data, cols);
  . nn_do_submit(data, nn, mean, std, cols);
  . nn_do_score(data, nn, mean, std, cols, tids = [42])

 . reference
  . http://www.physnet.uni-hamburg.de/physnet/matlab/help/toolbox/nnet/newff.html
   . explain why I get a out of memory

 . status
  . b7f5ad17ecc1ff45189a39b4db59256a87aaa640
   . un data/fu.csv a commiter
   . si ca marche bien, il faudrait augmenter le nmobre de neurones
   . sinon, essayer sur de nouveau tids
   
. doc on auc
 . http://matlabdatamining.blogspot.com/2007/06/roc-curves-and-auc.html
 . roc curves on wikipedia
 . the idea behind roc curves
  . if we have a binary classifier relying upon a threshold to map the input
   . for instance, if C(i) > 0.5 prediction = 1 else prediction = 0;
  . if we want to know the effect of varying the threshold
   . if (C(i) > T[i]) ...
  . then we can plot flase positives versus true positive
  . ROC space
   . true positive rate and false positive rates are needed

. machine learning references
 . http://crsouza.blogspot.com/